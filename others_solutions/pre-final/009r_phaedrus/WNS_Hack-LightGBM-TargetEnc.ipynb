{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from fastai.structured import *\n",
    "from fastai.column_data import *\n",
    "np.set_printoptions(threshold=50, edgeitems=20)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "from lightgbm import LGBMClassifier\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score ,roc_curve,auc\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold,KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "seed = 45\n",
    "#seed =145\n",
    "% matplotlib inline\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train:(54808, 14) test:(23490, 13) submission:(23490, 2)\n"
     ]
    }
   ],
   "source": [
    "### read data\n",
    "PATH='F:/AV/WNS'\n",
    "train_csv = 'train_LZdllcl.csv'\n",
    "test_csv = 'test_2umaH9m.csv'\n",
    "submit_csv = 'sample_submission_M0L0uXE.csv'\n",
    "\n",
    "### read train, test and submission files\n",
    "train = pd.read_csv(f'{PATH}/{train_csv}')\n",
    "test = pd.read_csv(f'{PATH}/{test_csv}')\n",
    "submission = pd.read_csv(f'{PATH}/{submit_csv}')\n",
    "\n",
    "print(\"Shape of {}:{} {}:{} {}:{}\".format('train',train.shape,'test',test.shape,'submission',submission.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>department</th>\n",
       "      <th>region</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>recruitment_channel</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>is_promoted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65438</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_7</td>\n",
       "      <td>Master's &amp; above</td>\n",
       "      <td>f</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65141</td>\n",
       "      <td>Operations</td>\n",
       "      <td>region_22</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7513</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_19</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2542</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_23</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48945</td>\n",
       "      <td>Technology</td>\n",
       "      <td>region_26</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id         department     region         education gender  \\\n",
       "0        65438  Sales & Marketing   region_7  Master's & above      f   \n",
       "1        65141         Operations  region_22        Bachelor's      m   \n",
       "2         7513  Sales & Marketing  region_19        Bachelor's      m   \n",
       "3         2542  Sales & Marketing  region_23        Bachelor's      m   \n",
       "4        48945         Technology  region_26        Bachelor's      m   \n",
       "\n",
       "  recruitment_channel  no_of_trainings  age  previous_year_rating  \\\n",
       "0            sourcing                1   35                   5.0   \n",
       "1               other                1   30                   5.0   \n",
       "2            sourcing                1   34                   3.0   \n",
       "3               other                2   39                   1.0   \n",
       "4               other                1   45                   3.0   \n",
       "\n",
       "   length_of_service  KPIs_met >80%  awards_won?  avg_training_score  \\\n",
       "0                  8              1            0                  49   \n",
       "1                  4              0            0                  60   \n",
       "2                  7              0            0                  50   \n",
       "3                 10              0            0                  50   \n",
       "4                  2              0            0                  73   \n",
       "\n",
       "   is_promoted  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### inspect data\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50140\n",
       "1     4668\n",
       "Name: is_promoted, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### class balance\n",
    "\n",
    "train['is_promoted'].value_counts()\n",
    "\n",
    "## so approx 10% of past employees have been promoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### lets check if there is any repeat in employees\n",
    "\n",
    "len(train['employee_id'].unique()) == train.shape[0]\n",
    "\n",
    "### so all IDs are unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education               2409\n",
       "previous_year_rating    4124\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## null values\n",
    "\n",
    "null_columns=train.columns[train.isnull().any()]\n",
    "train[null_columns].isnull().sum()\n",
    "\n",
    "## so 2 columns have null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2409, 14) (6148, 14)\n"
     ]
    }
   ],
   "source": [
    "### inspect null value columns\n",
    "a = train[(train.education.isnull())]\n",
    "_ = train[(train.education.isnull() | train.previous_year_rating.isnull())]\n",
    "\n",
    "print(a.shape,_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(a.index).intersection(set(_.index)) == set(a.index)\n",
    "\n",
    "### so everywhere where education is not present prev year rating is also not present, but vice-versa is not true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>department</th>\n",
       "      <th>region</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>recruitment_channel</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>is_promoted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>29934</td>\n",
       "      <td>Technology</td>\n",
       "      <td>region_23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>33332</td>\n",
       "      <td>Operations</td>\n",
       "      <td>region_15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>71177</td>\n",
       "      <td>Procurement</td>\n",
       "      <td>region_5</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>74759</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_4</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>35465</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>17423</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>45709</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_31</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>f</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>26599</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_16</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>9150</td>\n",
       "      <td>Analytics</td>\n",
       "      <td>region_22</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>f</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>77981</td>\n",
       "      <td>Finance</td>\n",
       "      <td>region_22</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    employee_id         department     region   education gender  \\\n",
       "10        29934         Technology  region_23         NaN      m   \n",
       "21        33332         Operations  region_15         NaN      m   \n",
       "23        71177        Procurement   region_5  Bachelor's      m   \n",
       "29        74759  Sales & Marketing   region_4  Bachelor's      m   \n",
       "32        35465  Sales & Marketing   region_7         NaN      f   \n",
       "43        17423  Sales & Marketing   region_2         NaN      m   \n",
       "56        45709  Sales & Marketing  region_31  Bachelor's      f   \n",
       "58        26599  Sales & Marketing  region_16  Bachelor's      m   \n",
       "62         9150          Analytics  region_22  Bachelor's      f   \n",
       "66        77981            Finance  region_22  Bachelor's      m   \n",
       "\n",
       "   recruitment_channel  no_of_trainings  age  previous_year_rating  \\\n",
       "10            sourcing                1   30                   NaN   \n",
       "21            sourcing                1   41                   4.0   \n",
       "23               other                1   27                   NaN   \n",
       "29            sourcing                1   26                   NaN   \n",
       "32            sourcing                1   24                   1.0   \n",
       "43               other                3   24                   2.0   \n",
       "56               other                1   29                   NaN   \n",
       "58               other                2   27                   NaN   \n",
       "62               other                1   28                   NaN   \n",
       "66               other                1   27                   NaN   \n",
       "\n",
       "    length_of_service  KPIs_met >80%  awards_won?  avg_training_score  \\\n",
       "10                  1              0            0                  77   \n",
       "21                 11              0            0                  57   \n",
       "23                  1              0            0                  70   \n",
       "29                  1              0            0                  44   \n",
       "32                  2              0            0                  48   \n",
       "43                  2              0            0                  48   \n",
       "56                  1              0            0                  49   \n",
       "58                  1              1            0                  47   \n",
       "62                  1              1            0                  80   \n",
       "66                  1              1            1                  58   \n",
       "\n",
       "    is_promoted  \n",
       "10            0  \n",
       "21            0  \n",
       "23            0  \n",
       "29            0  \n",
       "32            0  \n",
       "43            0  \n",
       "56            0  \n",
       "58            0  \n",
       "62            0  \n",
       "66            1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07091737150292778 0.08675738086604706\n"
     ]
    }
   ],
   "source": [
    "### check avg % of people promoted with NA in previous ye rating vs without NA\n",
    "\n",
    "print(np.mean(_['is_promoted']),np.mean(train[~train.education.isnull()]['is_promoted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0506434205064342 0.08675738086604706\n"
     ]
    }
   ],
   "source": [
    "### check avg % of people promoted with NA in education vs without NA\n",
    "\n",
    "print(np.mean(a['is_promoted']),np.mean(train[~train.education.isnull()]['is_promoted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For education we will use unknown for all missing values and 9999 for prev year training\n",
    "\n",
    "train['education'] = train.education.fillna('unknown')\n",
    "train['previous_year_rating'] = train.previous_year_rating.fillna(9999)\n",
    "\n",
    "test['education'] = test.education.fillna('unknown')\n",
    "test['previous_year_rating'] = test.previous_year_rating.fillna(9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78298, 14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### merge dataframes for ease of processing\n",
    "Y = train['is_promoted'].values\n",
    "train.drop('is_promoted',inplace=True,axis=1)\n",
    "train['train'] = 'train'\n",
    "test['train'] = 'test'\n",
    "merged = pd.concat([train,test])\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['department',\n",
       " 'region',\n",
       " 'education',\n",
       " 'gender',\n",
       " 'recruitment_channel',\n",
       " 'train',\n",
       " 'KPIs_met >80%',\n",
       " 'awards_won?']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = [i for i in merged.columns if merged[i].dtypes == 'object']+['KPIs_met >80%','awards_won?']\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['department', 'region', 'education', 'gender', 'recruitment_channel', 'KPIs_met >80%', 'awards_won?']\n"
     ]
    }
   ],
   "source": [
    "cat_cols.remove('train')\n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "\n",
    "def target_encode(trn_series=None, \n",
    "                  tst_series=None, \n",
    "                  target=None, \n",
    "                  min_samples_leaf=1, \n",
    "                  smoothing=1,\n",
    "                  noise_level=0):\n",
    "    \"\"\"\n",
    "    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n",
    "    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n",
    "    trn_series : training categorical feature as a pd.Series\n",
    "    tst_series : test categorical feature as a pd.Series\n",
    "    target : target data as a pd.Series\n",
    "    min_samples_leaf (int) : minimum samples to take category average into account\n",
    "    smoothing (int) : smoothing effect to balance categorical average vs prior  \n",
    "    \"\"\" \n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    # Compute target mean \n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "    # Compute smoothing\n",
    "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "    # Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=trn_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_trn_series.index = trn_series.index \n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    return add_noise(ft_trn_series, noise_level), add_noise(ft_tst_series, noise_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\Pytorch_env\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "new_tr, new_tst = merged[merged['train']=='train'],merged[merged['train']=='test']\n",
    "new_tr['is_promoted'] = Y\n",
    "\n",
    "# trn, sub = target_encode(new_tr[\"department\"], \n",
    "#                          new_tst[\"department\"], \n",
    "#                          target=new_tr.is_promoted, \n",
    "#                          min_samples_leaf=100,\n",
    "#                          smoothing=10,\n",
    "#                          noise_level=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\Pytorch_env\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "for i in ['department','region']:\n",
    "    new_tr[i], new_tst[i] = target_encode(new_tr[i], \n",
    "                         new_tst[i], \n",
    "                         target=new_tr.is_promoted, \n",
    "                         min_samples_leaf=75,\n",
    "                         smoothing=10,\n",
    "                         noise_level=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\Pytorch_env\\lib\\site-packages\\pandas\\core\\frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(78298, 14)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = new_tr['is_promoted'].values\n",
    "new_tr.drop('is_promoted',axis=1,inplace=True)\n",
    "merged = pd.concat([new_tr,new_tst])\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['education', 'gender', 'recruitment_channel', 'KPIs_met >80%', 'awards_won?']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = [i for i in merged.columns if merged[i].dtypes == 'object']+['KPIs_met >80%','awards_won?']\n",
    "cat_cols.remove('train')\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(df,cat_cols):\n",
    "    one_hot_encoded_training_predictors = pd.get_dummies(df[cat_cols])\n",
    "    df.drop(cat_cols,inplace=True,axis=1)\n",
    "    _ = pd.concat([df,one_hot_encoded_training_predictors],1)\n",
    "    new_tr, new_tst = _[_['train']=='train'],_[_['train']=='test']\n",
    "    new_tr.drop('train',inplace=True,axis=1)\n",
    "    new_tst.drop('train',inplace=True,axis=1)\n",
    "    return new_tr, new_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\Pytorch_env\\lib\\site-packages\\pandas\\core\\frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "train_OHE,test_OHE = pre_process(merged,cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>department</th>\n",
       "      <th>region</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>education_Bachelor's</th>\n",
       "      <th>education_Below Secondary</th>\n",
       "      <th>education_Master's &amp; above</th>\n",
       "      <th>education_unknown</th>\n",
       "      <th>gender_f</th>\n",
       "      <th>gender_m</th>\n",
       "      <th>recruitment_channel_other</th>\n",
       "      <th>recruitment_channel_referred</th>\n",
       "      <th>recruitment_channel_sourcing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65438</td>\n",
       "      <td>0.072006</td>\n",
       "      <td>0.106547</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65141</td>\n",
       "      <td>0.090020</td>\n",
       "      <td>0.114154</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7513</td>\n",
       "      <td>0.072152</td>\n",
       "      <td>0.060548</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2542</td>\n",
       "      <td>0.072122</td>\n",
       "      <td>0.116371</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48945</td>\n",
       "      <td>0.107660</td>\n",
       "      <td>0.063315</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id  department    region  no_of_trainings  age  \\\n",
       "0        65438    0.072006  0.106547                1   35   \n",
       "1        65141    0.090020  0.114154                1   30   \n",
       "2         7513    0.072152  0.060548                1   34   \n",
       "3         2542    0.072122  0.116371                2   39   \n",
       "4        48945    0.107660  0.063315                1   45   \n",
       "\n",
       "   previous_year_rating  length_of_service  avg_training_score  KPIs_met >80%  \\\n",
       "0                   5.0                  8                  49              1   \n",
       "1                   5.0                  4                  60              0   \n",
       "2                   3.0                  7                  50              0   \n",
       "3                   1.0                 10                  50              0   \n",
       "4                   3.0                  2                  73              0   \n",
       "\n",
       "   awards_won?  education_Bachelor's  education_Below Secondary  \\\n",
       "0            0                     0                          0   \n",
       "1            0                     1                          0   \n",
       "2            0                     1                          0   \n",
       "3            0                     1                          0   \n",
       "4            0                     1                          0   \n",
       "\n",
       "   education_Master's & above  education_unknown  gender_f  gender_m  \\\n",
       "0                           1                  0         1         0   \n",
       "1                           0                  0         0         1   \n",
       "2                           0                  0         0         1   \n",
       "3                           0                  0         0         1   \n",
       "4                           0                  0         0         1   \n",
       "\n",
       "   recruitment_channel_other  recruitment_channel_referred  \\\n",
       "0                          0                             0   \n",
       "1                          1                             0   \n",
       "2                          0                             0   \n",
       "3                          1                             0   \n",
       "4                          1                             0   \n",
       "\n",
       "   recruitment_channel_sourcing  \n",
       "0                             1  \n",
       "1                             0  \n",
       "2                             1  \n",
       "3                             0  \n",
       "4                             0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_OHE.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_lightgbm(train_df,test_df, target,num_folds, stratified = False, debug= False,modelname=\"lightgbm_0\"):\n",
    "    # Divide in training/validation and test data\n",
    "    train_df = train_df\n",
    "    test_df = test_df\n",
    "    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "    gc.collect()\n",
    "\n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=seed)\n",
    "    else:\n",
    "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=seed)\n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = [f for f in train_df.columns if f not in ['employee_id','index','train']]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], target)):\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], target[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], target[valid_idx]\n",
    "\n",
    "        # LightGBM parameters found by Bayesian optimization\n",
    "        clf = LGBMClassifier(\n",
    "            nthread=4,\n",
    "            n_estimators=5000,\n",
    "            learning_rate=0.005,\n",
    "#            num_leaves=34,\n",
    "#            colsample_bytree=0.9,\n",
    "#            subsample=0.8715623,\n",
    "            max_depth=10,\n",
    "            reg_alpha=.35,\n",
    "            reg_lambda=1.75,\n",
    "#            min_split_gain=0.0222415,\n",
    "#            min_child_weight=50,\n",
    "            silent=-1,\n",
    "            verbose=-1, )\n",
    "\n",
    "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "            eval_metric= 'auc', verbose= 100, early_stopping_rounds= 200)\n",
    "\n",
    "        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "        sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        print('Fold %2d F-score : %.6f' % (n_fold + 1, sklearn.metrics.f1_score(valid_y, (oof_preds[valid_idx]>0.3).astype(int))))\n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    print('Full f1 score %.6f' % sklearn.metrics.f1_score(target, (oof_preds>0.3).astype(int)))\n",
    "    \n",
    "    # Write submission file and plot feature importance\n",
    "    if not debug:\n",
    "        _ = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        Fname = 'F:/AV/WNS/submission/'+str(modelname)+'_'+str(_)+'.csv'\n",
    "        submission['is_promoted'] = sub_preds\n",
    "        submission[['employee_id', 'is_promoted']].to_csv(Fname, index= False)\n",
    "        oof = pd.DataFrame(oof_preds)\n",
    "        score = sklearn.metrics.f1_score(target, (oof_preds>0.3).astype(int))\n",
    "        oof.columns = [modelname+'_'+str(round(score,4))]\n",
    "        OOF_Fname = 'F:/AV/WNS/oof/'+str(modelname)+'_'+str(_)+'.csv'\n",
    "        oof.to_csv(OOF_Fname,index=False)\n",
    "    #display_importances(feature_importance_df)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LightGBM. Train shape: (54808, 19), test shape: (23490, 19)\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.897872\tvalid_1's auc: 0.893472\n",
      "[200]\ttraining's auc: 0.905838\tvalid_1's auc: 0.900283\n",
      "[300]\ttraining's auc: 0.910182\tvalid_1's auc: 0.905675\n",
      "[400]\ttraining's auc: 0.91341\tvalid_1's auc: 0.907438\n",
      "[500]\ttraining's auc: 0.91568\tvalid_1's auc: 0.908457\n",
      "[600]\ttraining's auc: 0.917546\tvalid_1's auc: 0.909389\n",
      "[700]\ttraining's auc: 0.919598\tvalid_1's auc: 0.910017\n",
      "[800]\ttraining's auc: 0.921379\tvalid_1's auc: 0.910478\n",
      "[900]\ttraining's auc: 0.923504\tvalid_1's auc: 0.910717\n",
      "[1000]\ttraining's auc: 0.925142\tvalid_1's auc: 0.911111\n",
      "[1100]\ttraining's auc: 0.927141\tvalid_1's auc: 0.911277\n",
      "[1200]\ttraining's auc: 0.929027\tvalid_1's auc: 0.911237\n",
      "[1300]\ttraining's auc: 0.930731\tvalid_1's auc: 0.91122\n",
      "Early stopping, best iteration is:\n",
      "[1149]\ttraining's auc: 0.928086\tvalid_1's auc: 0.911293\n",
      "Fold  1 F-score : 0.531429\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.896483\tvalid_1's auc: 0.893174\n",
      "[200]\ttraining's auc: 0.907814\tvalid_1's auc: 0.904797\n",
      "[300]\ttraining's auc: 0.910613\tvalid_1's auc: 0.907756\n",
      "[400]\ttraining's auc: 0.912701\tvalid_1's auc: 0.909486\n",
      "[500]\ttraining's auc: 0.914862\tvalid_1's auc: 0.911068\n",
      "[600]\ttraining's auc: 0.916443\tvalid_1's auc: 0.911742\n",
      "[700]\ttraining's auc: 0.918537\tvalid_1's auc: 0.912149\n",
      "[800]\ttraining's auc: 0.920347\tvalid_1's auc: 0.912485\n",
      "[900]\ttraining's auc: 0.922304\tvalid_1's auc: 0.913205\n",
      "[1000]\ttraining's auc: 0.924268\tvalid_1's auc: 0.913823\n",
      "[1100]\ttraining's auc: 0.925997\tvalid_1's auc: 0.914012\n",
      "[1200]\ttraining's auc: 0.9278\tvalid_1's auc: 0.914046\n",
      "[1300]\ttraining's auc: 0.929523\tvalid_1's auc: 0.914007\n",
      "[1400]\ttraining's auc: 0.931196\tvalid_1's auc: 0.913987\n",
      "Early stopping, best iteration is:\n",
      "[1230]\ttraining's auc: 0.928323\tvalid_1's auc: 0.914118\n",
      "Fold  2 F-score : 0.527349\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.898517\tvalid_1's auc: 0.881551\n",
      "[200]\ttraining's auc: 0.909795\tvalid_1's auc: 0.895451\n",
      "[300]\ttraining's auc: 0.912126\tvalid_1's auc: 0.897778\n",
      "[400]\ttraining's auc: 0.914502\tvalid_1's auc: 0.899643\n",
      "[500]\ttraining's auc: 0.916294\tvalid_1's auc: 0.900063\n",
      "[600]\ttraining's auc: 0.917911\tvalid_1's auc: 0.901274\n",
      "[700]\ttraining's auc: 0.919968\tvalid_1's auc: 0.902635\n",
      "[800]\ttraining's auc: 0.921718\tvalid_1's auc: 0.903554\n",
      "[900]\ttraining's auc: 0.923312\tvalid_1's auc: 0.904366\n",
      "[1000]\ttraining's auc: 0.925028\tvalid_1's auc: 0.904757\n",
      "[1100]\ttraining's auc: 0.926791\tvalid_1's auc: 0.905151\n",
      "[1200]\ttraining's auc: 0.928887\tvalid_1's auc: 0.905548\n",
      "[1300]\ttraining's auc: 0.930861\tvalid_1's auc: 0.905571\n",
      "[1400]\ttraining's auc: 0.932619\tvalid_1's auc: 0.90529\n",
      "Early stopping, best iteration is:\n",
      "[1270]\ttraining's auc: 0.930273\tvalid_1's auc: 0.905709\n",
      "Fold  3 F-score : 0.515195\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.896992\tvalid_1's auc: 0.888043\n",
      "[200]\ttraining's auc: 0.907108\tvalid_1's auc: 0.895733\n",
      "[300]\ttraining's auc: 0.91006\tvalid_1's auc: 0.89932\n",
      "[400]\ttraining's auc: 0.91371\tvalid_1's auc: 0.90387\n",
      "[500]\ttraining's auc: 0.915706\tvalid_1's auc: 0.905248\n",
      "[600]\ttraining's auc: 0.917452\tvalid_1's auc: 0.905846\n",
      "[700]\ttraining's auc: 0.919282\tvalid_1's auc: 0.906569\n",
      "[800]\ttraining's auc: 0.921371\tvalid_1's auc: 0.907519\n",
      "[900]\ttraining's auc: 0.923233\tvalid_1's auc: 0.908357\n",
      "[1000]\ttraining's auc: 0.925426\tvalid_1's auc: 0.908926\n",
      "[1100]\ttraining's auc: 0.927327\tvalid_1's auc: 0.909196\n",
      "[1200]\ttraining's auc: 0.929058\tvalid_1's auc: 0.909595\n",
      "[1300]\ttraining's auc: 0.930508\tvalid_1's auc: 0.910054\n",
      "[1400]\ttraining's auc: 0.932134\tvalid_1's auc: 0.910396\n",
      "[1500]\ttraining's auc: 0.933595\tvalid_1's auc: 0.910509\n",
      "[1600]\ttraining's auc: 0.935064\tvalid_1's auc: 0.910517\n",
      "[1700]\ttraining's auc: 0.93655\tvalid_1's auc: 0.910608\n",
      "[1800]\ttraining's auc: 0.937871\tvalid_1's auc: 0.910559\n",
      "Early stopping, best iteration is:\n",
      "[1679]\ttraining's auc: 0.936223\tvalid_1's auc: 0.910648\n",
      "Fold  4 F-score : 0.497159\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.895538\tvalid_1's auc: 0.890869\n",
      "[200]\ttraining's auc: 0.907767\tvalid_1's auc: 0.902493\n",
      "[300]\ttraining's auc: 0.910432\tvalid_1's auc: 0.904313\n",
      "[400]\ttraining's auc: 0.913118\tvalid_1's auc: 0.906223\n",
      "[500]\ttraining's auc: 0.915837\tvalid_1's auc: 0.90725\n",
      "[600]\ttraining's auc: 0.91778\tvalid_1's auc: 0.907878\n",
      "[700]\ttraining's auc: 0.920125\tvalid_1's auc: 0.90812\n",
      "[800]\ttraining's auc: 0.922437\tvalid_1's auc: 0.908334\n",
      "[900]\ttraining's auc: 0.924575\tvalid_1's auc: 0.908494\n",
      "[1000]\ttraining's auc: 0.926551\tvalid_1's auc: 0.908766\n",
      "[1100]\ttraining's auc: 0.928394\tvalid_1's auc: 0.909301\n",
      "[1200]\ttraining's auc: 0.930362\tvalid_1's auc: 0.909507\n",
      "[1300]\ttraining's auc: 0.932202\tvalid_1's auc: 0.909447\n",
      "[1400]\ttraining's auc: 0.933951\tvalid_1's auc: 0.909273\n",
      "Early stopping, best iteration is:\n",
      "[1202]\ttraining's auc: 0.930392\tvalid_1's auc: 0.909534\n",
      "Fold  5 F-score : 0.531250\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.895319\tvalid_1's auc: 0.894548\n",
      "[200]\ttraining's auc: 0.907404\tvalid_1's auc: 0.909319\n",
      "[300]\ttraining's auc: 0.910471\tvalid_1's auc: 0.912213\n",
      "[400]\ttraining's auc: 0.912621\tvalid_1's auc: 0.913751\n",
      "[500]\ttraining's auc: 0.915139\tvalid_1's auc: 0.914581\n",
      "[600]\ttraining's auc: 0.916998\tvalid_1's auc: 0.915058\n",
      "[700]\ttraining's auc: 0.918723\tvalid_1's auc: 0.915701\n",
      "[800]\ttraining's auc: 0.9205\tvalid_1's auc: 0.916458\n",
      "[900]\ttraining's auc: 0.922369\tvalid_1's auc: 0.917263\n",
      "[1000]\ttraining's auc: 0.924058\tvalid_1's auc: 0.917671\n",
      "[1100]\ttraining's auc: 0.92588\tvalid_1's auc: 0.917972\n",
      "[1200]\ttraining's auc: 0.927609\tvalid_1's auc: 0.918235\n",
      "[1300]\ttraining's auc: 0.929357\tvalid_1's auc: 0.918379\n",
      "[1400]\ttraining's auc: 0.931333\tvalid_1's auc: 0.918255\n",
      "[1500]\ttraining's auc: 0.933097\tvalid_1's auc: 0.918015\n",
      "Early stopping, best iteration is:\n",
      "[1327]\ttraining's auc: 0.929874\tvalid_1's auc: 0.918447\n",
      "Fold  6 F-score : 0.536377\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.899648\tvalid_1's auc: 0.89223\n",
      "[200]\ttraining's auc: 0.909175\tvalid_1's auc: 0.901419\n",
      "[300]\ttraining's auc: 0.912198\tvalid_1's auc: 0.904121\n",
      "[400]\ttraining's auc: 0.91405\tvalid_1's auc: 0.905138\n",
      "[500]\ttraining's auc: 0.916238\tvalid_1's auc: 0.906421\n",
      "[600]\ttraining's auc: 0.917852\tvalid_1's auc: 0.907915\n",
      "[700]\ttraining's auc: 0.919693\tvalid_1's auc: 0.908496\n",
      "[800]\ttraining's auc: 0.921678\tvalid_1's auc: 0.909379\n",
      "[900]\ttraining's auc: 0.923663\tvalid_1's auc: 0.909735\n",
      "[1000]\ttraining's auc: 0.925373\tvalid_1's auc: 0.910204\n",
      "[1100]\ttraining's auc: 0.927297\tvalid_1's auc: 0.910234\n",
      "[1200]\ttraining's auc: 0.929287\tvalid_1's auc: 0.910446\n",
      "[1300]\ttraining's auc: 0.930942\tvalid_1's auc: 0.910405\n",
      "[1400]\ttraining's auc: 0.932639\tvalid_1's auc: 0.910284\n",
      "Early stopping, best iteration is:\n",
      "[1224]\ttraining's auc: 0.929644\tvalid_1's auc: 0.91054\n",
      "Fold  7 F-score : 0.511628\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.894553\tvalid_1's auc: 0.895092\n",
      "[200]\ttraining's auc: 0.907971\tvalid_1's auc: 0.907781\n",
      "[300]\ttraining's auc: 0.910685\tvalid_1's auc: 0.909124\n",
      "[400]\ttraining's auc: 0.913458\tvalid_1's auc: 0.910071\n",
      "[500]\ttraining's auc: 0.91508\tvalid_1's auc: 0.910751\n",
      "[600]\ttraining's auc: 0.9171\tvalid_1's auc: 0.911725\n",
      "[700]\ttraining's auc: 0.918958\tvalid_1's auc: 0.912512\n",
      "[800]\ttraining's auc: 0.920673\tvalid_1's auc: 0.913237\n",
      "[900]\ttraining's auc: 0.92251\tvalid_1's auc: 0.913918\n",
      "[1000]\ttraining's auc: 0.92409\tvalid_1's auc: 0.914223\n",
      "[1100]\ttraining's auc: 0.92567\tvalid_1's auc: 0.914049\n",
      "[1200]\ttraining's auc: 0.927687\tvalid_1's auc: 0.91396\n",
      "Early stopping, best iteration is:\n",
      "[1035]\ttraining's auc: 0.924571\tvalid_1's auc: 0.914281\n",
      "Fold  8 F-score : 0.481426\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.894673\tvalid_1's auc: 0.88894\n",
      "[200]\ttraining's auc: 0.908024\tvalid_1's auc: 0.897019\n",
      "[300]\ttraining's auc: 0.910725\tvalid_1's auc: 0.898843\n",
      "[400]\ttraining's auc: 0.913597\tvalid_1's auc: 0.900965\n",
      "[500]\ttraining's auc: 0.915747\tvalid_1's auc: 0.902336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600]\ttraining's auc: 0.917422\tvalid_1's auc: 0.903389\n",
      "[700]\ttraining's auc: 0.919349\tvalid_1's auc: 0.904946\n",
      "[800]\ttraining's auc: 0.921076\tvalid_1's auc: 0.90557\n",
      "[900]\ttraining's auc: 0.922841\tvalid_1's auc: 0.905869\n",
      "[1000]\ttraining's auc: 0.925115\tvalid_1's auc: 0.906023\n",
      "[1100]\ttraining's auc: 0.927109\tvalid_1's auc: 0.906123\n",
      "[1200]\ttraining's auc: 0.928872\tvalid_1's auc: 0.906182\n",
      "[1300]\ttraining's auc: 0.930755\tvalid_1's auc: 0.90624\n",
      "[1400]\ttraining's auc: 0.932421\tvalid_1's auc: 0.906515\n",
      "[1500]\ttraining's auc: 0.93405\tvalid_1's auc: 0.906957\n",
      "[1600]\ttraining's auc: 0.935671\tvalid_1's auc: 0.907219\n",
      "[1700]\ttraining's auc: 0.937218\tvalid_1's auc: 0.907373\n",
      "[1800]\ttraining's auc: 0.93865\tvalid_1's auc: 0.907475\n",
      "[1900]\ttraining's auc: 0.940068\tvalid_1's auc: 0.907388\n",
      "[2000]\ttraining's auc: 0.941447\tvalid_1's auc: 0.907601\n",
      "[2100]\ttraining's auc: 0.942756\tvalid_1's auc: 0.907861\n",
      "[2200]\ttraining's auc: 0.943942\tvalid_1's auc: 0.907811\n",
      "[2300]\ttraining's auc: 0.945146\tvalid_1's auc: 0.907662\n",
      "Early stopping, best iteration is:\n",
      "[2130]\ttraining's auc: 0.94315\tvalid_1's auc: 0.907924\n",
      "Fold  9 F-score : 0.504348\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.894643\tvalid_1's auc: 0.882654\n",
      "[200]\ttraining's auc: 0.906428\tvalid_1's auc: 0.897398\n",
      "[300]\ttraining's auc: 0.911207\tvalid_1's auc: 0.901352\n",
      "[400]\ttraining's auc: 0.913057\tvalid_1's auc: 0.903281\n",
      "[500]\ttraining's auc: 0.915291\tvalid_1's auc: 0.904467\n",
      "[600]\ttraining's auc: 0.916936\tvalid_1's auc: 0.904948\n",
      "[700]\ttraining's auc: 0.91894\tvalid_1's auc: 0.905049\n",
      "[800]\ttraining's auc: 0.920677\tvalid_1's auc: 0.905739\n",
      "[900]\ttraining's auc: 0.922544\tvalid_1's auc: 0.906739\n",
      "[1000]\ttraining's auc: 0.924368\tvalid_1's auc: 0.907232\n",
      "[1100]\ttraining's auc: 0.926031\tvalid_1's auc: 0.907571\n",
      "[1200]\ttraining's auc: 0.927901\tvalid_1's auc: 0.907749\n",
      "[1300]\ttraining's auc: 0.929742\tvalid_1's auc: 0.907999\n",
      "[1400]\ttraining's auc: 0.931425\tvalid_1's auc: 0.90817\n",
      "[1500]\ttraining's auc: 0.932908\tvalid_1's auc: 0.90822\n",
      "[1600]\ttraining's auc: 0.934285\tvalid_1's auc: 0.908382\n",
      "[1700]\ttraining's auc: 0.935721\tvalid_1's auc: 0.908679\n",
      "[1800]\ttraining's auc: 0.9371\tvalid_1's auc: 0.909093\n",
      "[1900]\ttraining's auc: 0.938468\tvalid_1's auc: 0.909507\n",
      "[2000]\ttraining's auc: 0.939829\tvalid_1's auc: 0.909837\n",
      "[2100]\ttraining's auc: 0.941119\tvalid_1's auc: 0.910059\n",
      "[2200]\ttraining's auc: 0.94231\tvalid_1's auc: 0.910163\n",
      "[2300]\ttraining's auc: 0.943435\tvalid_1's auc: 0.91032\n",
      "[2400]\ttraining's auc: 0.944645\tvalid_1's auc: 0.910478\n",
      "[2500]\ttraining's auc: 0.945872\tvalid_1's auc: 0.910647\n",
      "[2600]\ttraining's auc: 0.947029\tvalid_1's auc: 0.910715\n",
      "[2700]\ttraining's auc: 0.948015\tvalid_1's auc: 0.910766\n",
      "[2800]\ttraining's auc: 0.948997\tvalid_1's auc: 0.910809\n",
      "[2900]\ttraining's auc: 0.950025\tvalid_1's auc: 0.910946\n",
      "[3000]\ttraining's auc: 0.951065\tvalid_1's auc: 0.911045\n",
      "[3100]\ttraining's auc: 0.952121\tvalid_1's auc: 0.911145\n",
      "[3200]\ttraining's auc: 0.953128\tvalid_1's auc: 0.911255\n",
      "[3300]\ttraining's auc: 0.954082\tvalid_1's auc: 0.911277\n",
      "[3400]\ttraining's auc: 0.954931\tvalid_1's auc: 0.911282\n",
      "[3500]\ttraining's auc: 0.955802\tvalid_1's auc: 0.911331\n",
      "[3600]\ttraining's auc: 0.95662\tvalid_1's auc: 0.911368\n",
      "[3700]\ttraining's auc: 0.95751\tvalid_1's auc: 0.911339\n",
      "[3800]\ttraining's auc: 0.958431\tvalid_1's auc: 0.911512\n",
      "[3900]\ttraining's auc: 0.95934\tvalid_1's auc: 0.911796\n",
      "[4000]\ttraining's auc: 0.960154\tvalid_1's auc: 0.911828\n",
      "[4100]\ttraining's auc: 0.961153\tvalid_1's auc: 0.911781\n",
      "[4200]\ttraining's auc: 0.961819\tvalid_1's auc: 0.91183\n",
      "Early stopping, best iteration is:\n",
      "[4026]\ttraining's auc: 0.960434\tvalid_1's auc: 0.91189\n",
      "Fold 10 F-score : 0.528150\n",
      "Full f1 score 0.516690\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "oof = kfold_lightgbm(train_OHE,test_OHE, Y,num_folds=10, stratified = True, debug= True,modelname=\"lightgbm_10fld_targetenc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
