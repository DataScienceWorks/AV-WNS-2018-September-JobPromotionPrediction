{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from fastai.structured import *\n",
    "from fastai.column_data import *\n",
    "np.set_printoptions(threshold=50, edgeitems=20)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "from lightgbm import LGBMClassifier\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score ,roc_curve,auc\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold,KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "seed = 45\n",
    "#seed =145\n",
    "% matplotlib inline\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read data\n",
    "PATH='F:/AV/WNS'\n",
    "train_csv = 'train_LZdllcl.csv'\n",
    "test_csv = 'test_2umaH9m.csv'\n",
    "submit_csv = 'sample_submission_M0L0uXE.csv'\n",
    "\n",
    "### read train, test and submission files\n",
    "train = pd.read_csv(f'{PATH}/{train_csv}')\n",
    "test = pd.read_csv(f'{PATH}/{test_csv}')\n",
    "submission = pd.read_csv(f'{PATH}/{submit_csv}')\n",
    "\n",
    "print(\"Shape of {}:{} {}:{} {}:{}\".format('train',train.shape,'test',test.shape,'submission',submission.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### inspect data\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### class balance\n",
    "\n",
    "train['is_promoted'].value_counts()\n",
    "\n",
    "## so approx 10% of past employees have been promoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### lets check if there is any repeat in employees\n",
    "\n",
    "len(train['employee_id'].unique()) == train.shape[0]\n",
    "\n",
    "### so all IDs are unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## null values\n",
    "\n",
    "null_columns=train.columns[train.isnull().any()]\n",
    "train[null_columns].isnull().sum()\n",
    "\n",
    "## so 2 columns have null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### inspect null value columns\n",
    "a = train[(train.education.isnull())]\n",
    "_ = train[(train.education.isnull() | train.previous_year_rating.isnull())]\n",
    "\n",
    "print(a.shape,_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(a.index).intersection(set(_.index)) == set(a.index)\n",
    "\n",
    "### so everywhere where education is not present prev year rating is also not present, but vice-versa is not true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check avg % of people promoted with NA in previous ye rating vs without NA\n",
    "\n",
    "print(np.mean(_['is_promoted']),np.mean(train[~train.education.isnull()]['is_promoted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check avg % of people promoted with NA in education vs without NA\n",
    "\n",
    "print(np.mean(a['is_promoted']),np.mean(train[~train.education.isnull()]['is_promoted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For education we will use unknown for all missing values and 9999 for prev year training\n",
    "\n",
    "train['education'] = train.education.fillna('unknown')\n",
    "train['previous_year_rating'] = train.previous_year_rating.fillna(9999)\n",
    "\n",
    "test['education'] = test.education.fillna('unknown')\n",
    "test['previous_year_rating'] = test.previous_year_rating.fillna(9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### merge dataframes for ease of processing\n",
    "Y = train['is_promoted'].values\n",
    "train.drop('is_promoted',inplace=True,axis=1)\n",
    "train['train'] = 'train'\n",
    "test['train'] = 'test'\n",
    "merged = pd.concat([train,test])\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [i for i in merged.columns if merged[i].dtypes == 'object']+['KPIs_met >80%','awards_won?']\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols.remove('train')\n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "import mlcrate as mlc\n",
    "import pickle as pkl\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Embedding, Dense, Flatten, Concatenate, Dot, Reshape, Add, Subtract\n",
    "from keras import objectives\n",
    "from keras import backend as K\n",
    "from keras import regularizers \n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random as rn\n",
    "def init_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "    # The below is necessary for starting Numpy generated random numbers\n",
    "    # in a well-defined initial state.\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # The below is necessary for starting core Python generated random numbers\n",
    "    # in a well-defined state.\n",
    "\n",
    "    rn.seed(seed)\n",
    "\n",
    "    # Force TensorFlow to use single thread.\n",
    "    # Multiple threads are a potential source of\n",
    "    # non-reproducible results.\n",
    "    # For further details, see: https://stackoverflow.com/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res\n",
    "\n",
    "    session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "    from keras import backend as K\n",
    "\n",
    "    # The below tf.set_random_seed() will make random number generation\n",
    "    # in the TensorFlow backend have a well-defined initial state.\n",
    "    # For further details, see: https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "\n",
    "    tf.set_random_seed(seed)\n",
    "\n",
    "    sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "    K.set_session(sess)\n",
    "    return sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self,columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "\n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        '''\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = LabelEncoder().fit_transform(output[col])\n",
    "        else:\n",
    "            for colname,col in output.iteritems():\n",
    "                output[colname] = LabelEncoder().fit_transform(col)\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['department', 'region', 'education']\n",
    "f_size  = [len(merged[f].unique()) + 1 for f in features]\n",
    "f_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_1 = merged.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = MultiColumnLabelEncoder(columns = features).fit_transform(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged.groupby(features)['employee_id'].count()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.unstack().fillna(0)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.stack().astype('float32')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.log1p(X).reset_index()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns=features + ['num']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = MultiColumnLabelEncoder(columns = features).fit_transform(X)\n",
    "# print(merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [X[f].values for f in features]\n",
    "y_train = (X[['num']].values).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X.num > 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_latent = 2\n",
    "embedding_reg = 0.0002\n",
    "kernel_reg = 0.1\n",
    "\n",
    "def get_embed(x_input, x_size, k_latent):\n",
    "    if x_size > 0: #category\n",
    "        embed = Embedding(x_size, k_latent, input_length=1, \n",
    "                          embeddings_regularizer=l2(embedding_reg))(x_input)\n",
    "        embed = Flatten()(embed)\n",
    "    else:\n",
    "        embed = Dense(k_latent, kernel_regularizer=l2(embedding_reg))(x_input)\n",
    "    return embed\n",
    "\n",
    "def build_model_1(X, f_size):\n",
    "    dim_input = len(f_size)\n",
    "    \n",
    "    input_x = [Input(shape=(1,)) for i in range(dim_input)] \n",
    "     \n",
    "    biases = [get_embed(x, size, 1) for (x, size) in zip(input_x, f_size)]\n",
    "    \n",
    "    factors = [get_embed(x, size, k_latent) for (x, size) in zip(input_x, f_size)]\n",
    "    \n",
    "    s = Add()(factors)\n",
    "    \n",
    "    diffs = [Subtract()([s, x]) for x in factors]\n",
    "    \n",
    "    dots = [Dot(axes=1)([d, x]) for d,x in zip(diffs, factors)]\n",
    "    \n",
    "    x = Concatenate()(biases + dots)\n",
    "    x = BatchNormalization()(x)\n",
    "    output = Dense(1, activation='relu', kernel_regularizer=l2(kernel_reg))(x)\n",
    "    model = Model(inputs=input_x, outputs=[output])\n",
    "    opt = Adam(clipnorm=0.5)\n",
    "    model.compile(optimizer=opt, loss='mean_squared_error')\n",
    "    output_f = factors + biases\n",
    "    model_features = Model(inputs=input_x, outputs=output_f)\n",
    "    return model, model_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, model_features = build_model_1(X_train, f_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_features.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10000\n",
    "P = 17\n",
    "try:\n",
    "    del sess\n",
    "except:\n",
    "    pass\n",
    "sess = init_seeds(0)\n",
    "\n",
    "batch_size = 2**P\n",
    "print(batch_size)\n",
    "model, model_features = build_model_1(X_train, f_size)\n",
    "earlystopper = EarlyStopping(patience=250, verbose=1)\n",
    "\n",
    "model.fit(X_train,  y_train, \n",
    "          epochs=n_epochs, batch_size=batch_size, verbose=1, shuffle=True, \n",
    "          validation_data=(X_train, y_train), \n",
    "          sample_weight=None,\n",
    "          callbacks=[earlystopper],\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = model_features.predict(X_train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = X_pred[:len(features)]\n",
    "\n",
    "biases = X_pred[len(features):2*len(features)]\n",
    "\n",
    "for f, X_p in zip(features, factors):\n",
    "    for i in range(k_latent):\n",
    "        X['%s_fm_factor_%d' % (f, i)] = X_p[:,i]\n",
    "\n",
    "for f, X_p in zip(features, biases):\n",
    "    X['%s_fm_bias' % (f)] = X_p[:,0]\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.to_csv('F:/AV/WNS/Interaction_feats.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =pd.read_csv('F:/AV/WNS/Interaction_feats.csv')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = X.copy()\n",
    "_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feats in tqdm(features):\n",
    "#     feat1 = feats+'_fm_factor_0'\n",
    "#     feat2 = feats+'_fm_factor_1'\n",
    "#     bias = feats+'_fm_bias'\n",
    "#     right_df = X[[feats,feat1,feat2,bias]]\n",
    "#     right_df = right_df.drop_duplicates()\n",
    "#     _ = merged[[feats]].merge(right_df,on=feats)\n",
    "#     _.to_csv('F:/AV/WNS/{}.csv'.format(feats),index=False)\n",
    "#     del right_df,_\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feats in tqdm(features):\n",
    "    feat1 = feats+'_fm_factor_0'\n",
    "    feat2 = feats+'_fm_factor_1'\n",
    "    bias = feats+'_fm_bias'\n",
    "    right_df = X[[feats,feat1,feat2,bias]]\n",
    "    right_df = right_df.drop_duplicates()\n",
    "    merged = merged.merge(right_df,on=feats)\n",
    "    merged[[feats]] = merged_1[[feats]].values\n",
    "    del right_df\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(df,cat_cols,drop_cats=True):\n",
    "    \n",
    "    if drop_cats:\n",
    "        df.drop(cat_cols,inplace=True,axis=1)\n",
    "        \n",
    "    try:\n",
    "        one_hot_encoded_training_predictors = pd.get_dummies(df[cat_cols])\n",
    "        temp = df.drop(cat_cols,inplace=False,axis=1)\n",
    "        _ = pd.concat([temp,one_hot_encoded_training_predictors],1)\n",
    "        new_tr, new_tst = _[_['train']=='train'],_[_['train']=='test']\n",
    "        new_tr.drop('train',inplace=True,axis=1)\n",
    "        new_tst.drop('train',inplace=True,axis=1)\n",
    "        del temp\n",
    "        return new_tr, new_tst\n",
    "    except:\n",
    "        new_tr, new_tst = df[df['train']=='train'],df[df['train']=='test']\n",
    "        new_tr.drop('train',inplace=True,axis=1)\n",
    "        new_tst.drop('train',inplace=True,axis=1)\n",
    "        return new_tr, new_tst\n",
    "    \n",
    "    #return new_tr, new_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_OHE,test_OHE = pre_process(merged,cat_cols,drop_cats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_lightgbm(train_df,test_df, target,num_folds, stratified = False, debug= False,modelname=\"lightgbm_0\",drop_cat=True):\n",
    "    # Divide in training/validation and test data\n",
    "    train_df = train_df\n",
    "    test_df = test_df\n",
    "    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "    gc.collect()\n",
    "\n",
    "    \n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=seed)\n",
    "    else:\n",
    "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=seed)\n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = [f for f in train_df.columns if f not in ['employee_id','index','train']]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], target)):\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], target[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], target[valid_idx]\n",
    "\n",
    "        # LightGBM parameters found by Bayesian optimization\n",
    "        clf = LGBMClassifier(\n",
    "            nthread=4,\n",
    "            n_estimators=5000,\n",
    "            learning_rate=0.001,\n",
    "#            num_leaves=34,\n",
    "#            colsample_bytree=0.9,\n",
    "#            subsample=0.8715623,\n",
    "            max_depth=8,\n",
    "            reg_alpha=1,\n",
    "            reg_lambda=1,\n",
    "#            min_split_gain=0.0222415,\n",
    "#            min_child_weight=50,\n",
    "            silent=-1,\n",
    "            verbose=-1, )\n",
    "\n",
    "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "            eval_metric= 'auc', verbose= 100, early_stopping_rounds= 200)\n",
    "\n",
    "        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "        sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "        print(oof_preds[:5])\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        print('Fold %2d F-score : %.6f' % (n_fold + 1, sklearn.metrics.f1_score(valid_y, (oof_preds[valid_idx]>0.3).astype(int))))\n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    print('Full f1 score %.6f' % sklearn.metrics.f1_score(target, (oof_preds>0.3).astype(int)))\n",
    "    \n",
    "    # Write submission file and plot feature importance\n",
    "    if not debug:\n",
    "        _ = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        Fname = 'F:/AV/WNS/submission/'+str(modelname)+'_'+str(_)+'.csv'\n",
    "        submission['is_promoted'] = sub_preds\n",
    "        submission[['employee_id', 'is_promoted']].to_csv(Fname, index= False)\n",
    "        oof = pd.DataFrame(oof_preds)\n",
    "        score = sklearn.metrics.f1_score(target, (oof_preds>0.3).astype(int))\n",
    "        oof.columns = [modelname+'_'+str(round(score,4))]\n",
    "        OOF_Fname = 'F:/AV/WNS/oof/'+str(modelname)+'_'+str(_)+'.csv'\n",
    "        oof.to_csv(OOF_Fname,index=False)\n",
    "    #display_importances(feature_importance_df)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "oof = kfold_lightgbm(train_OHE,test_OHE, Y,num_folds=10, stratified = True, debug= False,modelname=\"lightgbm_5fld_interactionfeatsonly\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
